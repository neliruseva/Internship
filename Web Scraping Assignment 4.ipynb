{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c53fe97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\nelir\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: selenium in c:\\users\\nelir\\anaconda3\\lib\\site-packages (4.15.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\nelir\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c21d421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b63f5",
   "metadata": {},
   "source": [
    "# Q1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "        \n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5026ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error managing chrome (error sending request for url (https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json): error trying to connect: An existing connection was forcibly closed by the remote host. (os error 10054)); using driver found in the cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e73737",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab3bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Date = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00cc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")\n",
    "        \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")\n",
    "        \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\"):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")\n",
    "        \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\"):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")\n",
    "        \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1144790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank), len(Name), len(Artist), len(Date), len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94bf0a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear ‚Äì Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Dark Horse\"[48]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[52]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear ‚Äì Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                             \"Lakdi Ki Kathi\"[44]   \n",
       "20  21.                                      \"Sorry\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.          \"Humpty the train on a fruits ride\"[47]   \n",
       "23  24.                                 \"Dark Horse\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                      \"Shree Hanuman Chalisa\"[52]   \n",
       "28  29.                             \"Girls Like You\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist        Upload Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                       Jingle Toons      June 14, 2018   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                         Katy Perry  February 20, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                          Passenger      July 25, 2012   \n",
       "26                                        Alan Walker   December 3, 2015   \n",
       "27                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   13.65  \n",
       "1    8.32  \n",
       "2    6.84  \n",
       "3    6.50  \n",
       "4    6.14  \n",
       "5    6.09  \n",
       "6    5.71  \n",
       "7    5.57  \n",
       "8    5.09  \n",
       "9    5.01  \n",
       "10   4.96  \n",
       "11   4.57  \n",
       "12   4.48  \n",
       "13   4.16  \n",
       "14   3.97  \n",
       "15   3.92  \n",
       "16   3.91  \n",
       "17   3.84  \n",
       "18   3.78  \n",
       "19   3.76  \n",
       "20   3.74  \n",
       "21   3.69  \n",
       "22   3.63  \n",
       "23   3.63  \n",
       "24   3.60  \n",
       "25   3.56  \n",
       "26   3.55  \n",
       "27   3.54  \n",
       "28   3.52  \n",
       "29   3.50  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"Rank\": Rank, \"Name\": Name, \"Artist\":Artist, \"Upload Date\": Date, \"Views\": Views})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f94aeb",
   "metadata": {},
   "source": [
    "# Q2: Scrape the details team India‚Äôs international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f9565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error managing chrome (error sending request for url (https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json): connection error: connection reset); using driver found in the cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddac978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f9f5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu=driver.find_element(By.XPATH, '/html/body/header/div[3]/div[1]/ul/div[1]/a[2]')\n",
    "menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e8c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd20337",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, '//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append(\"-\")\n",
    "    \n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"match-place ng-scope\"]'):\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append(\"-\")\n",
    "    \n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")\n",
    "    \n",
    "    \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Time.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "043ea54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(Series), len(Place), len(Date), len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b5e7403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>29 NOVEMBER, 2023</td>\n",
       "      <td>8:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>8:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Shaheed Veer Narayan Singh International Crick...</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>8:00 AM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>6 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>9 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Kingsmead, Durban</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>4:00 PM GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Series  \\\n",
       "0  ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "1  ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "2            AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "3  ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "4            AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "5        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "6        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "7        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "8         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "\n",
       "                                               Place               Date  \\\n",
       "0                           Wankhede Stadium, Mumbai  29 NOVEMBER, 2023   \n",
       "1                           Wankhede Stadium, Mumbai   1 DECEMBER, 2023   \n",
       "2  Shaheed Veer Narayan Singh International Crick...   1 DECEMBER, 2023   \n",
       "3                           Wankhede Stadium, Mumbai   3 DECEMBER, 2023   \n",
       "4                   M Chinnaswamy Stadium, Bengaluru   3 DECEMBER, 2023   \n",
       "5                           Wankhede Stadium, Mumbai   6 DECEMBER, 2023   \n",
       "6                           Wankhede Stadium, Mumbai   9 DECEMBER, 2023   \n",
       "7                           Wankhede Stadium, Mumbai  10 DECEMBER, 2023   \n",
       "8                                  Kingsmead, Durban  10 DECEMBER, 2023   \n",
       "\n",
       "          Time  \n",
       "0  8:00 AM GMT  \n",
       "1  8:00 AM GMT  \n",
       "2  1:30 PM GMT  \n",
       "3  8:00 AM GMT  \n",
       "4  1:30 PM GMT  \n",
       "5  1:30 PM GMT  \n",
       "6  1:30 PM GMT  \n",
       "7  1:30 PM GMT  \n",
       "8  4:00 PM GMT  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\"Series\": Series, \"Place\": Place, \"Date\": Date, \"Time\": Time})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64616173",
   "metadata": {},
   "source": [
    "# Q3: Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd8ecbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error managing chrome (error sending request for url (https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json): error trying to connect: An existing connection was forcibly closed by the remote host. (os error 10054)); using driver found in the cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c61738db",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2adbf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy=driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f34ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "india=driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14cf9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP=driver.find_element(By.XPATH, \"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "GDP.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98f2a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "State = []\n",
    "GSDP18_19 = []\n",
    "GSDP19_20 = []\n",
    "Share18_19 = []\n",
    "GDP_billion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91e0fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='display dataTable']/tbody/tr/td[1]\")[:67]:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "    \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP18_19.append(\"_\")\n",
    "    \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP19_20.append(\"_\")\n",
    "    \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share18_19.append(\"_\")\n",
    "    \n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5e7bb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 132 132 132 132 132\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank), len(State), len(GSDP18_19), len(GSDP19_20), len(Share18_19), len(GDP_billion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8043bfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 18-19</th>\n",
       "      <th>GSDP 19-20</th>\n",
       "      <th>Share 18-19</th>\n",
       "      <th>GDP billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>25,141</td>\n",
       "      <td>28,391</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>24,534</td>\n",
       "      <td>-</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>22,488</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>20,947</td>\n",
       "      <td>24,424</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                      State GSDP 18-19 GSDP 19-20 Share 18-19  \\\n",
       "0      1                Maharashtra  2,632,792          -      13.94%   \n",
       "1      2                 Tamil Nadu  1,630,208  1,845,853       8.63%   \n",
       "2      3              Uttar Pradesh  1,584,764  1,687,818       8.39%   \n",
       "3      4                    Gujarat  1,502,899          -       7.96%   \n",
       "4      5                  Karnataka  1,493,127  1,631,977       7.91%   \n",
       "..   ...                        ...        ...        ...         ...   \n",
       "127   29                     Sikkim     25,141     28,391       0.15%   \n",
       "128   30                   Nagaland     24,534          -       0.15%   \n",
       "129   31          Arunachal Pradesh     22,488          -       0.13%   \n",
       "130   32                    Mizoram     20,947     24,424       0.13%   \n",
       "131   33  Andaman & Nicobar Islands          -          -           -   \n",
       "\n",
       "    GDP billion  \n",
       "0       399.921  \n",
       "1       247.629  \n",
       "2       240.726  \n",
       "3       228.290  \n",
       "4       226.806  \n",
       "..          ...  \n",
       "127      17,060  \n",
       "128           -  \n",
       "129           -  \n",
       "130      17,797  \n",
       "131           -  \n",
       "\n",
       "[132 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame({\"Rank\": Rank, \"State\": State, \"GSDP 18-19\": GSDP18_19, \"GSDP 19-20\": GSDP19_20, \"Share 18-19\": Share18_19, \"GDP billion\": GDP_billion})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c80ade",
   "metadata": {},
   "source": [
    "# Q4: Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3892a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ebd897b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://github.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c2bb5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_down=driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "drop_down.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4a6d22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending=driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "72e6624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_counts =[]\n",
    "Language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e079b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]//a')\n",
    "for i in title[:22]:\n",
    "    try:\n",
    "        Repository_title.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append('-')\n",
    "\n",
    "description=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]//p') \n",
    "for i in description[:22]:\n",
    "    try:\n",
    "        Repository_description.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append('-')\n",
    "\n",
    "counts=driver.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"][1]') \n",
    "for i in counts[:22]:\n",
    "    try:\n",
    "        Contributors_counts.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_counts.append('-')\n",
    "\n",
    "languages=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]') \n",
    "for i in languages:\n",
    "    try:\n",
    "        Language.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08dbd9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 22 22 22\n"
     ]
    }
   ],
   "source": [
    "print(len(Repository_title), len(Repository_description), len(Contributors_counts), len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "64a56f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors counts</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LouisShark / chatgpt_system_prompt</td>\n",
       "      <td>store all agent's system prompt</td>\n",
       "      <td>2,171</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run-llama / rags</td>\n",
       "      <td>Build ChatGPT over your data, all with natural...</td>\n",
       "      <td>3,692</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linexjlin / GPTs</td>\n",
       "      <td>leaked prompts of GPTs</td>\n",
       "      <td>4,372</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Panel-dev / 1Panel</td>\n",
       "      <td>üî• üî• üî• Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø„ÄÇ</td>\n",
       "      <td>13,310</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GrowingGit / GitHub-Chinese-Top-Charts</td>\n",
       "      <td>üá®üá≥ GitHub‰∏≠ÊñáÊéíË°åÊ¶úÔºåÂêÑËØ≠Ë®ÄÂàÜËÆæ„ÄåËΩØ‰ª∂ | ËµÑÊñô„ÄçÊ¶úÂçïÔºåÁ≤æÂáÜÂÆö‰Ωç‰∏≠ÊñáÂ•ΩÈ°πÁõÆ„ÄÇÂêÑÂèñÊâÄÈúÄ...</td>\n",
       "      <td>70,519</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>atomicals / atomicals-js</td>\n",
       "      <td>Atomicals CLI and Javascript Library</td>\n",
       "      <td>442</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>opa334 / TrollStore</td>\n",
       "      <td>Jailed iOS app that can install IPAs permanent...</td>\n",
       "      <td>11,377</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jordan-cutler / path-to-senior-engineer-handbook</td>\n",
       "      <td>All the resources you need to get to Senior En...</td>\n",
       "      <td>3,051</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BurntSushi / ripgrep</td>\n",
       "      <td>ripgrep recursively searches directories for a...</td>\n",
       "      <td>41,449</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bgstaal / multipleWindow3dScene</td>\n",
       "      <td>A quick example of how one can \"synchronize\" a...</td>\n",
       "      <td>10,032</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ftindy / IPTV-URL</td>\n",
       "      <td>Open-source Android/Desktop remake of Civ V</td>\n",
       "      <td>634</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yairm210 / Unciv</td>\n",
       "      <td>A library for building applications in a consi...</td>\n",
       "      <td>6,759</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pointfreeco / swift-composable-architecture</td>\n",
       "      <td>12 Weeks, 24 Lessons, AI for All!</td>\n",
       "      <td>10,100</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>microsoft / AI-For-Beginners</td>\n",
       "      <td>Spring Boot</td>\n",
       "      <td>22,678</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spring-projects / spring-boot</td>\n",
       "      <td>A toolchain for web projects, aimed to provide...</td>\n",
       "      <td>70,610</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>biomejs / biome</td>\n",
       "      <td>Understanding Deep Learning - Simon J.D. Prince</td>\n",
       "      <td>4,636</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>udlbook / udlbook</td>\n",
       "      <td>JSON for Modern C++</td>\n",
       "      <td>3,384</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nlohmann / json</td>\n",
       "      <td>Code for CRATE (Coding RAte reduction Transfor...</td>\n",
       "      <td>37,668</td>\n",
       "      <td>Svelte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ma-Lab-Berkeley / CRATE</td>\n",
       "      <td>based on bgstaal/multipleWindow3dScene</td>\n",
       "      <td>817</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ShinoKana / multipleWindow3dScene</td>\n",
       "      <td>Bookmark manager for the wizards üßô</td>\n",
       "      <td>335</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>goniszewski / grimoire</td>\n",
       "      <td>K√≠nh chi·∫øu y√™uuuu qu·ª∑ seg hi·ªán raaa</td>\n",
       "      <td>864</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>zennomi / Seg-Mirror</td>\n",
       "      <td>A PHP client library for accessing Google APIs</td>\n",
       "      <td>175</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Repository title  \\\n",
       "0                 LouisShark / chatgpt_system_prompt   \n",
       "1                                   run-llama / rags   \n",
       "2                                   linexjlin / GPTs   \n",
       "3                                1Panel-dev / 1Panel   \n",
       "4             GrowingGit / GitHub-Chinese-Top-Charts   \n",
       "5                           atomicals / atomicals-js   \n",
       "6                                opa334 / TrollStore   \n",
       "7   jordan-cutler / path-to-senior-engineer-handbook   \n",
       "8                               BurntSushi / ripgrep   \n",
       "9                    bgstaal / multipleWindow3dScene   \n",
       "10                                 Ftindy / IPTV-URL   \n",
       "11                                  yairm210 / Unciv   \n",
       "12       pointfreeco / swift-composable-architecture   \n",
       "13                      microsoft / AI-For-Beginners   \n",
       "14                     spring-projects / spring-boot   \n",
       "15                                   biomejs / biome   \n",
       "16                                 udlbook / udlbook   \n",
       "17                                   nlohmann / json   \n",
       "18                           Ma-Lab-Berkeley / CRATE   \n",
       "19                 ShinoKana / multipleWindow3dScene   \n",
       "20                            goniszewski / grimoire   \n",
       "21                              zennomi / Seg-Mirror   \n",
       "\n",
       "                               Repository description Contributors counts  \\\n",
       "0                     store all agent's system prompt               2,171   \n",
       "1   Build ChatGPT over your data, all with natural...               3,692   \n",
       "2                              leaked prompts of GPTs               4,372   \n",
       "3                      üî• üî• üî• Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø„ÄÇ              13,310   \n",
       "4   üá®üá≥ GitHub‰∏≠ÊñáÊéíË°åÊ¶úÔºåÂêÑËØ≠Ë®ÄÂàÜËÆæ„ÄåËΩØ‰ª∂ | ËµÑÊñô„ÄçÊ¶úÂçïÔºåÁ≤æÂáÜÂÆö‰Ωç‰∏≠ÊñáÂ•ΩÈ°πÁõÆ„ÄÇÂêÑÂèñÊâÄÈúÄ...              70,519   \n",
       "5                Atomicals CLI and Javascript Library                 442   \n",
       "6   Jailed iOS app that can install IPAs permanent...              11,377   \n",
       "7   All the resources you need to get to Senior En...               3,051   \n",
       "8   ripgrep recursively searches directories for a...              41,449   \n",
       "9   A quick example of how one can \"synchronize\" a...              10,032   \n",
       "10        Open-source Android/Desktop remake of Civ V                 634   \n",
       "11  A library for building applications in a consi...               6,759   \n",
       "12                  12 Weeks, 24 Lessons, AI for All!              10,100   \n",
       "13                                        Spring Boot              22,678   \n",
       "14  A toolchain for web projects, aimed to provide...              70,610   \n",
       "15    Understanding Deep Learning - Simon J.D. Prince               4,636   \n",
       "16                                JSON for Modern C++               3,384   \n",
       "17  Code for CRATE (Coding RAte reduction Transfor...              37,668   \n",
       "18             based on bgstaal/multipleWindow3dScene                 817   \n",
       "19                 Bookmark manager for the wizards üßô                 335   \n",
       "20                K√≠nh chi·∫øu y√™uuuu qu·ª∑ seg hi·ªán raaa                 864   \n",
       "21     A PHP client library for accessing Google APIs                 175   \n",
       "\n",
       "       Language used  \n",
       "0                  C  \n",
       "1             Python  \n",
       "2                 Go  \n",
       "3               Java  \n",
       "4         TypeScript  \n",
       "5                  C  \n",
       "6               Rust  \n",
       "7         JavaScript  \n",
       "8             Kotlin  \n",
       "9              Swift  \n",
       "10  Jupyter Notebook  \n",
       "11              Java  \n",
       "12              Rust  \n",
       "13  Jupyter Notebook  \n",
       "14               C++  \n",
       "15            Python  \n",
       "16        JavaScript  \n",
       "17            Svelte  \n",
       "18        JavaScript  \n",
       "19               PHP  \n",
       "20                Go  \n",
       "21        TypeScript  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame({\"Repository title\": Repository_title, \"Repository description\": Repository_description, \"Contributors counts\":Contributors_counts, \"Language used\": Language})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafc5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56f7f11f",
   "metadata": {},
   "source": [
    "# Q5: Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c8f5ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "965cd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https:/www.billboard.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3aebfc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts_button=driver.find_element(By.XPATH, '/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "charts_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca4a7079",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100=driver.find_element(By.XPATH, '/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a')\n",
    "top_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "faa3c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_Name = []\n",
    "Artist_Name =[]\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db53605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(500): # scroll the page down\n",
    "        driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "        \n",
    "                \n",
    "song_name=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//h3 ')\n",
    "for i in song_name[0:100]:\n",
    "    try:\n",
    "        Song_Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Song_Name.append('-')\n",
    "        \n",
    "\n",
    "artist_name= driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]//li[1]//span')\n",
    "for i in artist_name[0:100]:\n",
    "    try:\n",
    "        Artist_Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist_Name.append('-')\n",
    "        \n",
    "\n",
    "last_week= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//li[4]')\n",
    "for i in last_week[0:100]:\n",
    "    try:\n",
    "        Last_week_rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Last_week_rank.append('-')\n",
    "        \n",
    "\n",
    "peak= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//li[5]')\n",
    "for i in peak[0:100]:\n",
    "    try:\n",
    "        Peak_rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Peak_rank.append('-')\n",
    "        \n",
    "    \n",
    "board= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//li[6]')\n",
    "for i in board[0:100]:\n",
    "    try:\n",
    "        Weeks_on_board.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Weeks_on_board.append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ea626f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Song_Name), len(Artist_Name), len(Last_week_rank), len(Peak_rank), len(Weeks_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ea563f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Different 'Round Here</td>\n",
       "      <td>Riley Green Featuring Luke Combs</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bongos</td>\n",
       "      <td>Cardi B &amp; Megan Thee Stallion</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>But I Got A Beer In My Hand</td>\n",
       "      <td>Luke Bryan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Calling For You</td>\n",
       "      <td>Drake Featuring 21 Savage</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mi Ex Tenia Razon</td>\n",
       "      <td>Karol G</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Song Name                       Artist Name  \\\n",
       "0                       Lovin On Me                       Jack Harlow   \n",
       "1                      Cruel Summer                      Taylor Swift   \n",
       "2                Paint The Town Red                          Doja Cat   \n",
       "3   All I Want For Christmas Is You                      Mariah Carey   \n",
       "4                            Snooze                               SZA   \n",
       "..                              ...                               ...   \n",
       "95            Different 'Round Here  Riley Green Featuring Luke Combs   \n",
       "96                           Bongos     Cardi B & Megan Thee Stallion   \n",
       "97      But I Got A Beer In My Hand                        Luke Bryan   \n",
       "98                  Calling For You         Drake Featuring 21 Savage   \n",
       "99                Mi Ex Tenia Razon                           Karol G   \n",
       "\n",
       "   Last week rank Peak rank Weeks on board  \n",
       "0               2         1              2  \n",
       "1                                       29  \n",
       "2               1         1             16  \n",
       "3                                       60  \n",
       "4               3         1             50  \n",
       "..            ...       ...            ...  \n",
       "95                                       2  \n",
       "96             36         1             11  \n",
       "97                                       6  \n",
       "98             58         3              4  \n",
       "99                                      14  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame({\"Song Name\": Song_Name, \"Artist Name\": Artist_Name, \"Last week rank\": Last_week_rank, \"Peak rank\": Peak_rank, \"Weeks on board\": Weeks_on_board})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b871c",
   "metadata": {},
   "source": [
    "# Q6: Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "051d1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d62211a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "97ccaefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8ed6b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[2]')  \n",
    "for i in book_name:\n",
    "    try:\n",
    "        Book_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Book_name.append('-')\n",
    "        \n",
    "author_name=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[3]') \n",
    "for i in author_name:\n",
    "    try:\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append('-')\n",
    "        \n",
    "volumes=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[4]') \n",
    "for i in volumes:\n",
    "    try:\n",
    "        Volumes_sold.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Volumes_sold.append('-')\n",
    "        \n",
    "publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[5]') \n",
    "for i in publisher:\n",
    "    try:\n",
    "        Publisher.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Publisher.append('-')\n",
    "        \n",
    "genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[6]') \n",
    "for i in genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f5d8652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Book_name), len(Author_name), len(Volumes_sold), len(Publisher), len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d68fb13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.DataFrame({\"Book Name\": Book_name, \"Author Name\": Author_name, \"Volumes sold\": Volumes_sold, \"Publisher\": Publisher, \"Genre\": Genre})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5a928",
   "metadata": {},
   "source": [
    "# Q7:Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8270ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8608756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\" https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5ea81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(500): \n",
    "        driver.execute_script(\"window.scrollBy(0,100)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa87416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a4c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=driver.find_elements(By.XPATH, '//h3[@class=\"lister-item-header\"]//a') \n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "    \n",
    "    \n",
    "year=driver.find_elements(By.XPATH, '//h3[@class=\"lister-item-header\"]//span[2]') \n",
    "for i in year:\n",
    "    try:\n",
    "        Year_span.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Year_span.append('-')\n",
    "   \n",
    "      \n",
    "genre=driver.find_elements(By.XPATH, '//p[@class=\"text-muted text-small\"]//span[5]') \n",
    "for i in genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append('-')\n",
    "        \n",
    "        \n",
    "time=driver.find_elements(By.XPATH, '//p[@class=\"text-muted text-small\"]//span[3]') \n",
    "for i in time:\n",
    "    try:\n",
    "        Run_time.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Run_time.append('-')\n",
    "        \n",
    "        \n",
    "ratings=driver.find_elements(By.XPATH, '//div[@class=\"ipl-rating-star small\"]')\n",
    "for i in ratings:\n",
    "    try:\n",
    "        Ratings.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Ratings.append('-')\n",
    "        \n",
    "        \n",
    "votes=driver.find_elements(By.XPATH, '//span[@name=\"nv\"]') \n",
    "for i in votes:\n",
    "    try:\n",
    "        Votes.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Votes.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc739599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name), len (Year_span), len(Genre), len(Run_time), len(Ratings), len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2902a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>4,189 min</td>\n",
       "      <td>2,226,676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>1,293,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>1,056,272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>310,129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>269,253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013‚Äì2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>53,278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017‚Äì2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>65,358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005‚Äì )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>213,175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015‚Äì2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>44,372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>278,065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016‚Äì2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013‚Äì2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017‚Äì2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005‚Äì )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015‚Äì2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "     Run time      Votes  \n",
       "0   4,189 min  2,226,676  \n",
       "1      51 min  1,293,610  \n",
       "2      44 min  1,056,272  \n",
       "3      60 min    310,129  \n",
       "4      43 min    269,253  \n",
       "..        ...        ...  \n",
       "95     42 min     53,278  \n",
       "96     50 min     65,358  \n",
       "97     42 min    213,175  \n",
       "98     45 min     44,372  \n",
       "99    572 min    278,065  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.DataFrame({\"Name\": Name, \"Year span\": Year_span, \"Genre\": Genre, \"Run time\": Run_time, \"Votes\": Votes})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa08ba2",
   "metadata": {},
   "source": [
    "# Q8: Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "358f1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb676579",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf059021",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_all=driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "view_all.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbb82103",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45752fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=driver.find_elements(By.XPATH, '//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for i in name:\n",
    "    try:\n",
    "        Dataset_Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_Name.append('-')\n",
    "        \n",
    "data_type=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]//div[1]//span')\n",
    "for i in data_type:\n",
    "    try:\n",
    "        Data_type.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "        \n",
    "        \n",
    "task=driver.find_elements(By.XPATH, '//div[@class=\"relative col-span-8 sm:col-span-7\"]//p')\n",
    "for i in task:\n",
    "    try:\n",
    "        Task.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "        \n",
    "\n",
    "attribute=driver.find_elements(By.XPATH, '//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]//div[2]')\n",
    "for i in attribute:\n",
    "    try:\n",
    "        Attribute_type.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "        \n",
    "\n",
    "instances=driver.find_elements(By.XPATH, '//div[@class=\"col-span-3 flex items-center gap-2\"][3]//span')\n",
    "for i in instances:\n",
    "    try:\n",
    "        No_of_instances.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "\n",
    "        \n",
    "no_attribute=driver.find_elements(By.XPATH, '//div[@class=\"col-span-3 flex items-center gap-2\"][4]//span') \n",
    "for i in no_attribute:\n",
    "    try:\n",
    "        No_of_attribute.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attribute.append('-')\n",
    "        \n",
    "        \n",
    "year=driver.find_elements(By.XPATH, '//table[@class=\"col-span-full my-2 table sm:col-start-2\"][1]//td[3]')\n",
    "for i in year:\n",
    "    try:\n",
    "        Year.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78374149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset_Name), len(Data_type), len(Task), len(Attribute_type), len(No_of_instances), len(No_of_attribute), len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "472fc57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Classification</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Classification</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Using chemical analysis to determine the origi...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Diagnostic Wisconsin Breast Cancer Database.</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Classification</td>\n",
       "      <td>This diabetes dataset is from AIM '94</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Images of 13,611 grains of 7 different registe...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Derived from simple hierarchical decision mode...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Two datasets are included, related to red and ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Classification</td>\n",
       "      <td>The data is related with direct marketing camp...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "      <td>2/14/2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name                   Data type  \\\n",
       "0                                  Iris              Classification   \n",
       "1                         Heart Disease              Classification   \n",
       "2                                 Adult              Classification   \n",
       "3                                  Wine              Classification   \n",
       "4  Breast Cancer Wisconsin (Diagnostic)              Classification   \n",
       "5                              Diabetes              Classification   \n",
       "6                      Dry Bean Dataset              Classification   \n",
       "7                        Car Evaluation              Classification   \n",
       "8                          Wine Quality  Classification, Regression   \n",
       "9                        Bank Marketing              Classification   \n",
       "\n",
       "                                                Task  \\\n",
       "0  A small classic dataset from Fisher, 1936. One...   \n",
       "1  4 databases: Cleveland, Hungary, Switzerland, ...   \n",
       "2  Predict whether income exceeds $50K/yr based o...   \n",
       "3  Using chemical analysis to determine the origi...   \n",
       "4       Diagnostic Wisconsin Breast Cancer Database.   \n",
       "5              This diabetes dataset is from AIM '94   \n",
       "6  Images of 13,611 grains of 7 different registe...   \n",
       "7  Derived from simple hierarchical decision mode...   \n",
       "8  Two datasets are included, related to red and ...   \n",
       "9  The data is related with direct marketing camp...   \n",
       "\n",
       "              Attribute type   No of instances No of attribute       Year  \n",
       "0                    Tabular     150 Instances      4 Features   7/1/1988  \n",
       "1               Multivariate     303 Instances     13 Features   7/1/1988  \n",
       "2               Multivariate  48.84K Instances     14 Features   5/1/1996  \n",
       "3                    Tabular     178 Instances     13 Features   7/1/1991  \n",
       "4               Multivariate     569 Instances     30 Features  11/1/1995  \n",
       "5  Multivariate, Time-Series       1 Instances     20 Features        N/A  \n",
       "6               Multivariate  13.61K Instances     16 Features  9/14/2020  \n",
       "7               Multivariate   1.73K Instances      6 Features   6/1/1997  \n",
       "8               Multivariate    4.9K Instances     12 Features  10/7/2009  \n",
       "9               Multivariate  45.21K Instances     17 Features  2/14/2012  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame({\"Dataset Name\": Dataset_Name, \"Data type\" :Data_type, \"Task\": Task, \"Attribute type\": Attribute_type, \"No of instances\": No_of_instances, \"No of attribute\": No_of_attribute, \"Year\":Year})\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6af7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
